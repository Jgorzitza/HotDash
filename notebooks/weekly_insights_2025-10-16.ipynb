{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Insight Packet \u2014 2025-10-16\n",
    "\n",
    "_Shell notebook for charts, narrative tables, and analyzer joins. Populate once Supabase credentials and fresh NDJSON export land._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- Configure Supabase + GA MCP environment variables before running.\n",
    "- Ensure `artifacts/logs/` has the latest NDJSON export from reliability.\n",
    "- Install required packages via `npm install` / `pip install -r notebooks/requirements.txt` if applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap shared config once credentials arrive.\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "SUPABASE_EXPORT_PATH = Path(\"artifacts/logs/supabase_decision_export_2025-10-10T07-29-39Z.ndjson\")\n",
    "\n",
    "if not SUPABASE_EXPORT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Expected NDJSON export missing: {SUPABASE_EXPORT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NDJSON export into memory for quick summaries.\n",
    "with SUPABASE_EXPORT_PATH.open(\"r\", encoding=\"utf-8\") as ndjson_file:\n",
    "    decision_records = [json.loads(line) for line in ndjson_file if line.strip()]\n",
    "\n",
    "if not decision_records:\n",
    "    raise ValueError(f\"NDJSON export {SUPABASE_EXPORT_PATH} is empty\")\n",
    "\n",
    "total_records = len(decision_records)\n",
    "success_count = sum(1 for row in decision_records if (row.get(\"status\") or \"\").upper() == \"SUCCESS\")\n",
    "failure_count = sum(1 for row in decision_records if (row.get(\"status\") or \"\").upper() not in (\"SUCCESS\", \"\"))\n",
    "timeout_ids = [row.get(\"decisionId\") for row in decision_records if (row.get(\"status\") or \"\").upper() == \"TIMEOUT\"]\n",
    "durations = [float(row.get(\"durationMs\", 0.0)) for row in decision_records if row.get(\"durationMs\") is not None]\n",
    "if durations:\n",
    "    durations_sorted = sorted(durations)\n",
    "    average_duration_ms = sum(durations_sorted) / len(durations_sorted)\n",
    "    p95_index = max(0, min(len(durations_sorted) - 1, math.ceil(0.95 * len(durations_sorted)) - 1))\n",
    "    p95_duration_ms = durations_sorted[p95_index]\n",
    "else:\n",
    "    average_duration_ms = 0.0\n",
    "    p95_duration_ms = 0.0\n",
    "\n",
    "retry_distribution = {}\n",
    "for row in decision_records:\n",
    "    attempts = int(row.get(\"attempt\", 1) or 1)\n",
    "    retry_distribution[attempts] = retry_distribution.get(attempts, 0) + 1\n",
    "retry_distribution = dict(sorted(retry_distribution.items()))\n",
    "\n",
    "failure_rate_pct = round((failure_count / total_records) * 100, 2) if total_records else 0.0\n",
    "\n",
    "decision_sync_snapshot = {\n",
    "    \"total\": total_records,\n",
    "    \"success\": success_count,\n",
    "    \"failure\": failure_count,\n",
    "    \"failure_rate_pct\": failure_rate_pct,\n",
    "    \"timeouts\": timeout_ids,\n",
    "    \"avg_duration_ms\": round(average_duration_ms, 2),\n",
    "    \"p95_duration_ms\": round(p95_duration_ms, 2),\n",
    "    \"retry_distribution\": retry_distribution,\n",
    "}\n",
    "\n",
    "decision_sync_snapshot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPI Trend Queries\n",
    "\n",
    "_Placeholder: replace with actual warehouse query pulls once Supabase credentials are unlocked._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fetch sales delta, SLA breach rate, traffic anomalies into data frames.\n",
    "sales_delta_trend = None\n",
    "sla_breach_trend = None\n",
    "traffic_anomaly_trend = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision-Sync Analyzer Join\n",
    "\n",
    "_Placeholder: invoke scripts/ops/analyze-supabase-logs.ts and embed summary artifacts._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analyzer summary for downstream visualizations.\n",
    "ANALYZER_SUMMARY_PATH = Path(\"artifacts/monitoring/supabase-sync-summary-latest.json\")\n",
    "\n",
    "if ANALYZER_SUMMARY_PATH.exists():\n",
    "    with open(ANALYZER_SUMMARY_PATH, \"r\", encoding=\"utf-8\") as summary_file:\n",
    "        analyzer_summary = json.load(summary_file)\n",
    "else:\n",
    "    analyzer_summary = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Placeholders\n",
    "\n",
    "- Insert matplotlib/plotly charts for KPI trends.\n",
    "- Render analyzer pie chart + latency histograms.\n",
    "- Summarize GA MCP readiness checklist progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers will be populated once additional telemetry arrives.\n",
    "def render_kpi_trends():\n",
    "    return None\n",
    "\n",
    "def render_decision_sync_charts():\n",
    "    return decision_sync_snapshot\n",
    "\n",
    "def summarize_ga_mcp_readiness():\n",
    "    return {\n",
    "        \"status\": \"blocked\",\n",
    "        \"details\": \"Awaiting OCC-INF-221 staging credentials before GA MCP parity can run.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrative Draft\n",
    "\n",
    "_Use this section to draft the executive summary text and key callouts aligned with manager packet outline._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draft narrative populated with current telemetry snapshot.\n",
    "weekly_narrative = {\n",
    "    \"headline\": (\n",
    "        f\"Decision sync remains partially degraded with {decision_sync_snapshot['failure_rate_pct']}% failures across {decision_sync_snapshot['total']} records (timeouts: {decision_sync_snapshot['timeouts']}).\"\n",
    "    ),\n",
    "    \"decision_sync\": (\n",
    "        f\"Average latency sits at {decision_sync_snapshot['avg_duration_ms']} ms (p95 {decision_sync_snapshot['p95_duration_ms']} ms) with retry distribution {decision_sync_snapshot['retry_distribution']}.\"\n",
    "    ),\n",
    "    \"ga_mcp\": \"GA MCP contract tests remain blocked pending OCC-INF-221 credential drop; parity rerun queued once secrets land.\",\n",
    "    \"next_steps\": [\n",
    "        \"Monitor hourly NDJSON exports and append expanded metrics/visuals.\",\n",
    "        \"Coordinate with QA/design on modal asset capture once staging mock=0 stabilizes.\",\n",
    "        \"Generate KPI trend queries after telemetry parity validates live data.\",\n",
    "    ],\n",
    "}\n",
    "weekly_narrative\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}