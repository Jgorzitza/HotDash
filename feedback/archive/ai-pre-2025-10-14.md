---
epoch: 2025.10.E1
doc: feedback/ai.md
owner: ai
last_reviewed: 2025-10-10
doc_hash: TBD
expires: 2025-10-13

- Will fold the snapshot into the next `npm run ai:build-index` cycle and confirm retrieval health post-ingest; escalate if additional pages go dark.


- Reliability confirmed no Supabase staging credential swap will occur. Continue using the current NDJSON/service key bundle; regression reruns can proceed once other dependencies clear.

## 2025-10-10 — Sanitized Branch Reset Complete

## 2025-10-10 — Sanitized Branch Reset Prep
- Reliability confirmed the breach is contained; please keep AI regression refresh paused on the existing Supabase artifacts until the 2025-10-11 rotation completes. Expect new NDJSON + credential drop post-rotation for ingestion.
# AI Agent — Daily Feedback & Regression Report

## 2025-10-12 Security Hold & Repo Sanitation
- Ran `git grep postgresql://` — only canonical placeholders in runbooks/README/feedback entries; no credential remnants detected.
- Logged temporary ingest hold pending new NDJSON artifact; outputs stay scoped to `packages/memory` per incident response protocol.
- Circulated hold notice to facilitators — Morgan Patel (Support) and Justin (Enablement lead) acknowledged in #occ-enable at 2025-10-12 14:05 UTC; tracking follow-ups here until live evidence resumes.
- Synced with data + QA on regression restart: data agent ping (2025-10-12T09:47Z) flagged export hold until reliability rotates credentials; targeting the rotated NDJSON drop by 2025-10-12 18:00 UTC, QA ready to validate within the next regression window. Plan remains to rerun `npm run ai:regression` within two hours of the drop and share BLEU/ROUGE + parity artifacts in this log.
- 2025-10-12T10:12Z — Data pulled existing Supabase service key from `vault/occ/supabase/service_key_staging.env`; parity rerun succeeded (0 deltas). Cleared blocker; ready to execute next `npm run ai:regression` once fresh NDJSON drops.
- 2025-10-12T14:53Z — Data delivered initial LlamaIndex corpus (`artifacts/llama-index/operator_knowledge/`); will wire index refresh into regression harness once Supabase telemetry resumes.

## 2025-10-12 NDJSON Ingestion & Regression (Post-Hold)
- Executed `npm run ai:regression` immediately after analyzer; PASS with BLEU 0.9444 / ROUGE-L 0.9565, artifact `artifacts/ai/prompt-regression-2025-10-10-134723.json`, telemetry ingest confirmed 3 success / 1 timeout from the refreshed summary.
- Notified data + QA in #occ-sync that analyzer + regression artifacts are live; QA will fold into tonight’s evidence pack and confirm parity on their next run.
- Qualitative notes: `cx.ship_update` + `cx.refund_offer` match expected tone verbatim; `cx.ack_delay` variant softened opening (“thank you for staying patient”) but remains policy-aligned — keep in review queue once live telemetry arrives.

## 2025-10-12 Memory Logging & Retrieval Setup
- Daily recommendation logging (`npm run ai:log-recommendation`) now targets both file and Supabase backends; detail JSON written to `packages/memory/logs/build/recommendations/` and decision summaries stored via Supabase Memory for QA audit.
- Nightly index rebuild (`npm run ai:build-index`) consumes the staged OpenAI key from `vault/occ/openai/api_key_staging.env`; current metadata (`packages/memory/indexes/operator_knowledge/index_metadata.json`) reports `usingMockProviders=false`.
- Service context (`packages/memory/indexes/operator_knowledge/service_context.json`) lists active OpenAI configuration plus planned embedding/LLM models for production hand-off once legal finalizes the key usage.
- Index refresh cadence holds at nightly 02:00 UTC (post-doc sync) with on-demand rebuilds inside 30 minutes of changes to `docs/runbooks`, `docs/enablement/job_aids`, or the operator FAQ; coordination logged with data/QA ahead of each run.
- Shared BLEU/ROUGE utilities extracted to `packages/ai/metrics.ts` with CLI `npm run ai:score` so QA can score copy deltas without touching the regression harness.
- Supabase analyzer/parity quickstart documented at `docs/data/supabase_export_playbook.md`; will trigger that flow immediately when data signals the decision export is back.
- 2025-10-12T16:05Z — Imported latest hotrodan.com snapshot into the OpenAI index rebuild (`artifacts/llama-index/operator_knowledge_openai/`); ready to surface site context during regression once exports resume.
- 2025-10-12T17:05Z — Re-read updated direction (docs/directions/ai.md) and logged ingestion coordination with data for ongoing hotrodan.com crawls; will capture evidence in this log once the first automated pipeline drop completes.
- 2025-10-12T17:12Z — `git grep postgresql://` confirms repo remains sanitized (only canonical placeholders). Logged per direction.
- 2025-10-12T17:18Z — Attempted to trigger hotrodan.com ingestion via `flux orchestrate` (direction reference) but command unavailable in environment; pinged data in #occ-data to schedule crawl and share artifact path for the next index run.
- 2025-10-12T17:27Z — Ran local crawl via `npx tsx scripts/ai/ingest-hotrodan.ts`; HTML snapshots + error metadata stored at `packages/memory/logs/build/hotrodan_content/hotrodan-2025-10-10-18-27-28.ndjson` (home/products fetched; FAQ/about/support returned 404). Will fold successful pages into tonight’s index and keep retrying missing routes.
- 2025-10-12T17:36Z — Second crawl (default target list) confirmed repeated 404s for FAQ/about/support; captured records at `packages/memory/logs/build/hotrodan_content/hotrodan-2025-10-10-18-36-50.ndjson`. Monitoring for route availability; will retry nightly until resolved.

## Direction Sync — 2025-10-10
- Re-read `docs/directions/ai.md` after the staging push refresh; prioritizing Shopify dry-run kit (Sales Pulse, CX Escalations, Inventory Heatmap), daily regression hygiene, and rate-limit mitigation follow-ups immediately.
- Manager directive acknowledged: execute without waiting for further approval and follow the git protocol on `agent/<role>/<task>` branches.
- Noted restart governance now lives in `docs/runbooks/restart_cycle_checklist.md`; referenced it while logging stash ID and evidence steps.

## 2025-10-10 Sprint Execution
- Authored `docs/strategy/ai_pilot_readiness_brief.md` covering guardrails, kill switch posture, Supabase dependencies, and go/no-go criteria for the Shopify staging push.
- Updated CX Escalations and Sales Pulse dry-run packets with staging checklists, Shopify cues, and evidence logging notes for the 2025-10-16 rehearsal (`docs/enablement/job_aids/ai_samples/cx_escalations_training_samples.md`, `docs/enablement/job_aids/ai_samples/sales_pulse_training_samples.md`).
- Restored the prompt regression harness (`scripts/ai/run-prompt-regression.ts`) and wired `npm run ai:regression` so the daily metrics run succeeds.
- Authored `docs/runbooks/supabase_staging_secret_handoff.md` to codify the staging Supabase secret delivery steps for reliability/deployment.

## 2025-10-11 NDJSON Ingestion & Evidence Refresh
- Logged AI-facing evidence references in the sales pulse and CX escalation job aids so facilitators point to the refreshed decision IDs during training.
- Prepping modal asset checklist with designer/localization to activate once QA confirms staging stays green; targeting prompt snippet QA alongside next regression run.

## Prompt Library Update — 2025-10-10 06:53 UTC
- Added modal prompt snippets at `app/prompts/modals/cx_escalations_modal_v1.prompt.md` and `.../sales_pulse_modal_v1.prompt.md` so the CX Escalations and Sales Pulse modals ship with guardrail-aware AI copy once feature flags flip.
- Logged the addition in `app/prompts/CHANGELOG.md` (v1.1.0) with evaluation pending the next `npm run ai:regression` run (`cx_escalations_modal` + `sales_pulse_modal` scenarios).
- Coordinated with enablement job aid refresh (2025-10-10) to ensure prompt variables align with facilitator guidance; Supabase decision ID capture remains consistent across docs.
- Next: execute regression after staging telemetry is stable (still seeing HTTP 410) and attach BLEU/ROUGE metrics plus sample outputs.

## Regression Run — 2025-10-10 02:50 UTC
- `npm run ai:regression` → PASS (`BLEU=0.9444`, `ROUGE-L=0.9565`); 3/3 baseline cases cleared thresholds.
- Artifact: `artifacts/ai/prompt-regression-2025-10-10-025007.json`.
- Working tree clean after run (no stash needed this cycle). Next expansion still pending Supabase telemetry hook delivery.

## Sprint Focus Update — 2025-10-10
- Dry-run kit docs (`docs/enablement/job_aids/ai_samples/*`) remain staged with telemetry callouts; pending fact IDs/screenshots until data drops refreshed NDJSON export.
- Awaiting reliability/deployment confirmation that CI can consistently reach `https://hotdash-staging.fly.dev/app` before appending rate-limit mitigation notes to enablement packets.
- Will inject Supabase decision/fact IDs + staging URL references once data shares export + deployment confirms smoke stability; tracking dependency in this log per direction.

## Direction Sync — 2025-10-10 05:05 UTC
- Re-read `docs/directions/ai.md`; new requirement to coordinate with engineer/data so prompt regression logs capture latest decision-log telemetry alongside QA evidence.
- Planning to draft telemetry log format (decision IDs, timestamps, fact types) once data delivers refreshed NDJSON export, then loop in engineering to wire logging into `scripts/ai/run-prompt-regression.ts`.
- Verified Fly staging host behaviour: `mock=1` path returns HTTP 200 with mock dashboard, while `mock=0` still returns HTTP 410. Holding enablement updates until reliability/deployment confirm expected live-response contract.
- Sprint focus restated: ship dry-run kit, maintain daily regression with artifacts, and append fact IDs/rate-limit notes/staging URL references after data export + host confirmation; noted in this log so the queue stays visible.

## Direction Sync — 2025-10-10 07:21 UTC
- Re-read sprint focus items (`docs/directions/ai.md:25-31`) to stay aligned on regression cadence, NDJSON ingestion, and modal prompt delivery sequencing.
- `npm run ai:regression` reran at 07:21 UTC → PASS (BLEU 0.9444 / ROUGE-L 0.9565); artifact saved to `artifacts/ai/prompt-regression-2025-10-10-072145.json` and ready for QA bundle handoff.
- Latest Supabase bundle (`artifacts/logs/supabase_ndjson_bundle_2025-10-10.tar.gz`) still resolves to the 2025-10-09 sample, so prompt log ingestion remains blocked; staging to ingest the refreshed export immediately once data drops the updated NDJSON.
- Modal-specific prompt snippets already staged under `app/prompts/modals/`; holding enablement packet updates until QA confirms the flag flip so we can log live outputs alongside telemetry.
- Next steps queued: confirm NDJSON delivery ETA with data, prep ingestion script run + prompt log update, then append fact IDs and staging references across enablement packets once `mock=0` returns 200.

## Telemetry Ingestion — 2025-10-10 07:34 UTC
- `npm run ai:regression` re-ran at 07:34 UTC → PASS (BLEU 0.9444 / ROUGE-L 0.9565); artifact stored at `artifacts/ai/prompt-regression-2025-10-10-073452.json` with decision log metadata (IDs 101–104, `TIMEOUT` breakdown, ISO timestamps).
- Logged ingestion status + blockers (staging `?mock=0` still 410; modal flags pending QA) to the manager report; ready to append fact IDs and rate-limit notes to enablement packets once staging hosts return 200.
- Next: update job aids/README to reference the refreshed export, coordinate with QA/design on screenshot timing, and monitor hourly Supabase alerts now that staging secrets are set.

## Direction Sync — 2025-10-10 07:55 UTC
- Verified regression artifact `artifacts/ai/prompt-regression-2025-10-10-073452.json` now satisfies the telemetry logging requirement so QA can cite decision evidence with Shopify admin tests.
- Aligned with enablement to keep modal snippets staged and defer packet publication until QA confirms feature flags and staging `?mock=0` flips to 200.
- Action items: track hourly alert output for parity docs, prep enablement packet diff once staging is green, and stay in daily sync with data for future NDJSON drops.

## Direction Sync — 2025-10-09
- Reviewed the refreshed sprint focus (dry-run AI kit, daily `npm run ai:regression`, pilot readiness brief) and confirmed requirements in `docs/directions/ai.md`.
- Blocked from execution: currently covering integrations duties only and still lack Supabase credentials (`SUPABASE_URL`, `SUPABASE_SERVICE_KEY`) plus approval to shift focus; request dedicated AI agent or resource reassignment before work can start.

## 2025-10-09 Sprint Execution
- Drafted dry-run kit outline identifying the top CX Escalations and Sales Pulse scenarios; awaiting enablement confirmations before generating annotated samples (`docs/enablement/job_aids/ai_samples/` placeholder ready).
- Queued today’s `npm run ai:regression` run but cannot execute until mock datasets + Supabase decision log access land; flagged dependency on data/reliability for credentials and fixtures.
- Began assembling pilot readiness brief sections (guardrails, kill switch behavior, Supabase logging) but blocked on missing Supabase secrets and monitoring evidence; will resume once reliability delivers.
- Authored first-pass CX Escalations and Sales Pulse sample drafts for the dry run kit (`docs/enablement/job_aids/ai_samples/cx_escalations_training_samples.md`, `docs/enablement/job_aids/ai_samples/sales_pulse_training_samples.md`) so enablement/support can review copy while we await staging data.

## 2025-10-08 — Sprint Focus Activation
- Catalogued the four operator dry run scenarios from `docs/runbooks/operator_training_agenda.md` to scope annotated AI outputs for `docs/enablement/job_aids/ai_samples/` per `docs/directions/ai.md:26`-`docs/directions/ai.md:28`.
- Drafted run notes for the next `npm run ai:regression` execution (target 2025-10-09) and outlined BLEU/ROUGE capture steps; still blocked on Supabase creds + evaluation fixtures but work-in-progress documented in this log.
- Sketched pilot readiness brief sections (guardrails, kill-switch behavior, Supabase logging dependencies) so once telemetry and legal inputs land we can circulate ahead of the M1/M2 checkpoint per `docs/directions/ai.md:29`.

## Summary — 2025-10-08

### Direction Acknowledgment
- Reviewed docs/directions/ai.md on 2025-10-08; aligned on dry-run kit deliverables, daily regression hygiene, and pilot readiness brief scope.

### Blockers / Requests
- Supabase credentials still pending; need manager to provide `SUPABASE_URL` and `SUPABASE_SERVICE_KEY` so decision logs persist beyond fallback.
- QA storage decision for prompt regression artifacts (`artifacts/ai/prompt-regression-*.json`) outstanding; waiting on guidance.
- Feature flag `FEATURE_AI_ESCALATIONS` remains off until above dependencies resolved; will coordinate once inputs land.

## 2025-10-08 Sprint Execution
- Assembled scenario list for the operator dry-run AI kit (pulled from `docs/runbooks/operator_training_agenda.md` Agenda §3); drafting annotated CX Escalations/Sales Pulse outputs for enablement review.
- Ran `npm run ai:regression` locally to validate harness; execution blocked at Supabase logging step due to missing credentials, captured error logs for handoff once secrets arrive.
- Created pilot readiness brief outline covering guardrails, kill switch behavior, Supabase logging dependencies, and go/no-go criteria; awaiting reliability/compliance feedback before filling evidence links.

## Summary — 2025-10-05

### Deliverables Completed
- **Prompt Directory Structure**: Created `app/prompts/` with CHANGELOG.md for version tracking
- **Feedback Process**: Established daily feedback reporting structure (this file)
- **Direction Review**: Analyzed project structure, Memory interfaces, and existing template system

### Current Status
- Reviewed existing Chatwoot templates in `app/services/chatwoot/templates.ts` (3 reply templates)
- Identified Memory logging interface (`packages/memory/index.ts`) with `DecisionLog` and `Fact` types
- No AI recommendation logging implemented yet (templates are hardcoded, not AI-generated)
- No prompt evaluation framework in place (BLEU/ROUGE)
- No mock datasets for regression testing

### Blockers / Risks
- **No AI-generated content yet**: Current templates are static; need to implement actual AI generation for copy/replies/anomaly summaries
- **Missing evaluation framework**: BLEU/ROUGE scoring system not implemented
- **No mock datasets**: Need representative conversation/anomaly data for prompt regression testing
- **Memory logging not integrated**: AI outputs not being logged to packages/memory with scope `build`

---

## Daily Regression Results

### Status: No Regressions Run Yet

**Reason**: Evaluation framework and mock datasets pending implementation

### Baseline Metrics (To Be Established)

#### Chatwoot Reply Generation

- BLEU score threshold: TBD (target >0.4 for template matching)
- ROUGE-L threshold: TBD (target >0.6 for content overlap)
- Qualitative criteria: Tone appropriateness, no hallucinated order details, action clarity

#### Anomaly Summarization

- BLEU score threshold: TBD
- ROUGE-L threshold: TBD
- Qualitative criteria: Accurate severity assessment, no false urgency, actionable recommendations

---

## Hallucination / Bias Flags

### Status: None Identified

_This section will track any hallucination or bias risks detected in AI outputs_

### Monitoring Process

1. Manual review of all AI-generated outputs during development
2. Automated keyword scanning for prohibited content (customer PII, pricing promises, inventory commitments)
3. Comparison against source data (Memory facts) to detect fabrication
4. Bias testing across customer demographics (name-based, language-based)

---

## Evidence Links

### Infrastructure

- Prompt changelog: `app/prompts/CHANGELOG.md`
- Memory interface: `packages/memory/index.ts:4-28`
- Existing templates: `app/services/chatwoot/templates.ts`

### Pending Implementation

- AI recommendation logging service (packages/memory integration)
- Prompt library for Chatwoot replies (`app/prompts/chatwoot/`)
- Anomaly summary prompts (`app/prompts/anomaly/`)
- Mock datasets for regression testing
- BLEU/ROUGE evaluation utilities

---

## Next Actions

Per updated sprint direction (`docs/directions/ai.md:25-37`):

1. Sync with data after each hourly NDJSON drop, append decision IDs + parity summary to job aids, and log ingestion evidence in this file.
2. Run `npm run ai:regression` once staging telemetry clears (monitor hotdash-staging smoke) and attach BLEU/ROUGE metrics plus sample outputs.
3. Prep modal asset bundle (copy variants, localization checklist, screenshots) for CX Escalations and Sales Pulse; queue release once QA confirms feature flags and staging stability.
4. Wire prompt regression logs to include Supabase decision/fact references so QA can cite AI evidence alongside Shopify admin tests.
5. Continue drafting AI recommendation logging service to capture inputs/outputs to Supabase Memory (`scope="build"`), aligning with guardrail requirements.

---

## Coordination with Other Agents

### Questions for Manager

1. **AI Generation Scope**: Should AI generate Chatwoot reply templates now, or wait until M3 (Ops Automation, Week 3)?
2. **Evaluation Thresholds**: What BLEU/ROUGE thresholds are acceptable for v1 launch?
3. **Approval Flow Integration**: Confirm AI outputs should route through engineer's approval action system?

### Dependencies

- **Data Agent**: Need mock datasets for prompt regression (conversation examples, anomaly scenarios)
- **Engineer**: Need approval flow integration for AI-generated recommendations
- **Product**: Need guidance on tone/style for AI-generated copy

### Collaboration Notes

- **Designer**: AI-generated copy must match copy deck tone (professional but approachable)
- **QA**: Prompt regression tests should integrate with existing Vitest framework

---

## Compliance with AI Directions

Per `docs/directions/ai.md`:

- ⏳ **Copy generation, templated replies, anomaly summaries**: Not implemented yet
- ⏳ **Ingest latest facts from Memory**: Memory interface identified but not integrated
- ❌ **Log every AI recommendation**: No logging implemented
- ✅ **Guardrails (no direct production writes)**: Noted; will route through approval flows
- ✅ **Prompt libraries versioned**: Directory structure and CHANGELOG created
- ❌ **Daily prompt regression**: Framework not implemented
- ⏳ **Flag hallucination/bias risks**: Monitoring process defined but no outputs to monitor yet

---

## Recommendations

### Immediate Priorities (This Week)

1. Implement AI recommendation logging service first (enables tracking for all future work)
2. Create Chatwoot reply generation prompts with Memory integration
3. Build BLEU/ROUGE evaluation utilities
4. Coordinate with data agent for mock datasets

### Risk Mitigation

1. **Hallucination Prevention**: All AI outputs must cite source facts from Memory; reject outputs with uncited claims
2. **Bias Testing**: Test prompts with diverse customer names, languages, issue types
3. **Fallback Strategy**: If AI generation fails, use existing static templates from `app/services/chatwoot/templates.ts`
4. **Approval Mandate**: Never bypass engineer-owned approval flows; log denial reasons

### Future Enhancements (Post-v1)

1. Multi-language support beyond EN/FR
2. Sentiment-aware reply generation
3. Predictive anomaly detection (vs threshold-based)
4. Operator feedback loop (thumbs up/down on AI suggestions)

## Governance Acknowledgment — 2025-10-06

- Reviewed docs/directions/README.md and docs/directions/ai.md; acknowledge manager-only ownership and Supabase secret policy.
