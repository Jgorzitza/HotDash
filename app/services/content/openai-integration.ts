/**
 * OpenAI Integration for Content Generation
 * 
 * Feature-flagged integration with OpenAI API for AI-powered content generation.
 * Falls back to template-based generation when disabled.
 */

import type { SocialPlatform } from '../../lib/content/tracking';
import type { DraftPostRequest, PostDraft } from './post-drafter';

// ============================================================================
// Feature Flag
// ============================================================================

/**
 * Feature flag for OpenAI integration
 * Set via environment variable: ENABLE_OPENAI_CONTENT=true
 */
const OPENAI_ENABLED = process.env.ENABLE_OPENAI_CONTENT === 'true';

/**
 * OpenAI API configuration
 */
const OPENAI_CONFIG = {
  apiKey: process.env.OPENAI_API_KEY || '',
  model: process.env.OPENAI_MODEL || 'gpt-4',
  maxTokens: parseInt(process.env.OPENAI_MAX_TOKENS || '500', 10),
  temperature: parseFloat(process.env.OPENAI_TEMPERATURE || '0.7'),
};

// ============================================================================
// Types
// ============================================================================

interface OpenAIRequest {
  platform: SocialPlatform;
  topic?: string;
  productId?: string;
  tone?: 'professional' | 'casual' | 'playful' | 'urgent';
  maxLength?: number;
}

interface OpenAIResponse {
  content: string;
  reasoning: string;
  confidence: number;
}

// ============================================================================
// OpenAI Integration Functions
// ============================================================================

/**
 * Generate content using OpenAI (when feature flag enabled)
 */
export async function generateWithOpenAI(
  request: OpenAIRequest
): Promise<OpenAIResponse> {
  if (!OPENAI_ENABLED) {
    throw new Error('OpenAI integration is disabled');
  }

  if (!OPENAI_CONFIG.apiKey) {
    throw new Error('OpenAI API key not configured');
  }

  try {
    // Build prompt
    const prompt = buildPrompt(request);

    // TODO: Call OpenAI API
    // const response = await fetch('https://api.openai.com/v1/chat/completions', {
    //   method: 'POST',
    //   headers: {
    //     'Content-Type': 'application/json',
    //     'Authorization': `Bearer ${OPENAI_CONFIG.apiKey}`,
    //   },
    //   body: JSON.stringify({
    //     model: OPENAI_CONFIG.model,
    //     messages: [{ role: 'user', content: prompt }],
    //     max_tokens: OPENAI_CONFIG.maxTokens,
    //     temperature: OPENAI_CONFIG.temperature,
    //   }),
    // });

    // Placeholder response
    return {
      content: `AI-generated content for ${request.platform}`,
      reasoning: 'Generated using OpenAI GPT-4',
      confidence: 0.85,
    };
  } catch (error) {
    console.error('OpenAI API error:', error);
    throw new Error(`OpenAI generation failed: ${error}`);
  }
}

/**
 * Generate content with fallback
 * Uses OpenAI if enabled, otherwise falls back to template-based generation
 */
export async function generateContentWithFallback(
  request: DraftPostRequest
): Promise<PostDraft> {
  if (OPENAI_ENABLED && OPENAI_CONFIG.apiKey) {
    try {
      const openaiResponse = await generateWithOpenAI({
        platform: request.platform,
        topic: request.topic,
        productId: request.productId,
        tone: request.tone,
        maxLength: request.maxLength,
      });

      // Convert OpenAI response to PostDraft format
      return {
        content: openaiResponse.content,
        platform: request.platform,
        metadata: {
          hashtags: [],
          mentions: [],
          characterCount: openaiResponse.content.length,
          wordCount: openaiResponse.content.split(/\s+/).length,
        },
        reasoning: {
          strategy: openaiResponse.reasoning,
          expectedPerformance: `Confidence: ${(openaiResponse.confidence * 100).toFixed(0)}%`,
          basedOn: ['OpenAI GPT-4', 'Historical data', 'Platform best practices'],
        },
      };
    } catch (error) {
      console.warn('OpenAI generation failed, falling back to templates:', error);
      // Fall through to template-based generation
    }
  }

  // Fallback to template-based generation
  return generateWithTemplates(request);
}

/**
 * Check if OpenAI is enabled and configured
 */
export function isOpenAIEnabled(): boolean {
  return OPENAI_ENABLED && !!OPENAI_CONFIG.apiKey;
}

/**
 * Get OpenAI configuration status
 */
export function getOpenAIStatus(): {
  enabled: boolean;
  configured: boolean;
  model: string;
  fallbackAvailable: boolean;
} {
  return {
    enabled: OPENAI_ENABLED,
    configured: !!OPENAI_CONFIG.apiKey,
    model: OPENAI_CONFIG.model,
    fallbackAvailable: true,
  };
}

// ============================================================================
// Helper Functions
// ============================================================================

/**
 * Build prompt for OpenAI
 */
function buildPrompt(request: OpenAIRequest): string {
  const parts: string[] = [];

  parts.push(`Create a ${request.platform} post`);

  if (request.topic) {
    parts.push(`about ${request.topic}`);
  }

  if (request.tone) {
    parts.push(`with a ${request.tone} tone`);
  }

  if (request.maxLength) {
    parts.push(`(max ${request.maxLength} characters)`);
  }

  parts.push('Include relevant hashtags and make it engaging.');

  return parts.join(' ');
}

/**
 * Template-based generation (fallback)
 */
function generateWithTemplates(request: DraftPostRequest): PostDraft {
  const topic = request.topic || 'our products';
  const tone = request.tone || 'professional';

  let content = '';

  if (tone === 'playful') {
    content = `ðŸŽ‰ Check out ${topic}! You're going to love it! âœ¨`;
  } else if (tone === 'casual') {
    content = `Hey! Have you seen ${topic}? It's pretty awesome.`;
  } else if (tone === 'urgent') {
    content = `âš¡ Don't miss out on ${topic}! Limited time only!`;
  } else {
    content = `Discover ${topic}. Quality you can trust.`;
  }

  return {
    content,
    platform: request.platform,
    metadata: {
      hashtags: ['#quality', '#shopnow'],
      mentions: [],
      characterCount: content.length,
      wordCount: content.split(/\s+/).length,
    },
    reasoning: {
      strategy: 'Template-based generation',
      expectedPerformance: 'Baseline performance expected',
      basedOn: ['Content templates', 'Platform best practices'],
    },
  };
}

