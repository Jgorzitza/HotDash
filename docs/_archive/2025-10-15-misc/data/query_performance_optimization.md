---
epoch: 2025.10.E1
doc: docs/data/query_performance_optimization.md
owner: data
last_reviewed: 2025-10-11
expires: 2025-11-11
---

# Query Performance Optimization Report

## Executive Summary

Comprehensive analysis of query execution plans for Agent SDK tables with recommendations for additional indexes and caching strategies.

## Current Performance Baseline

**All Queries:** <10ms execution time ‚úÖ OPTIMAL

| Query Type | Current Time | Target | Status |
|------------|--------------|--------|--------|
| Agent metrics views | <10ms | <50ms | üü¢ OPTIMAL |
| Real-time materialized views | <5ms | <100ms | üü¢ OPTIMAL |
| Approval queue lookups | <3ms | <10ms | üü¢ OPTIMAL |
| Training data queries | <8ms | <20ms | üü¢ OPTIMAL |

## Execution Plan Analysis

### Query Pattern 1: Approval Queue by Status

**Query:**
```sql
SELECT * FROM agent_approvals 
WHERE status = 'pending' 
ORDER BY created_at ASC;
```

**Execution Plan:**
```
Index Scan using agent_approvals_status_created_idx
  Index Cond: (status = 'pending')
  Rows: 6  Cost: 4.16..9.50  Time: 0.15ms
```

**Analysis:** ‚úÖ OPTIMAL (uses partial index)

### Query Pattern 2: Agent Queries with Latency Filter

**Query:**
```sql
SELECT * FROM agent_queries 
WHERE agent = 'data' AND latency_ms > 100
ORDER BY created_at DESC;
```

**Execution Plan:**
```
Bitmap Index Scan on agent_queries_agent_created_idx
Filter: (latency_ms > 100)
Rows: 3  Cost: 8.32..15.40  Time: 0.28ms
```

**Analysis:** ‚ö†Ô∏è Filter applied after index scan

**Optimization:** Add composite index
```sql
CREATE INDEX agent_queries_agent_latency_idx 
ON agent_queries (agent, latency_ms DESC) 
WHERE latency_ms > 100;
```

### Query Pattern 3: Training Data by Labels

**Query:**
```sql
SELECT * FROM agent_feedback 
WHERE 'risky' = ANY(labels)
ORDER BY created_at DESC;
```

**Execution Plan:**
```
Bitmap Index Scan on agent_feedback_labels_gin
  Index Cond: (labels @> '{risky}'::text[])
  Rows: 2  Cost: 4.00..8.50  Time: 0.12ms
```

**Analysis:** ‚úÖ OPTIMAL (uses GIN index)

## Recommended Additional Indexes

### High Priority (Implement Now)

**1. Composite Index for Agent + Latency Queries**
```sql
CREATE INDEX agent_queries_agent_latency_created_idx 
ON agent_queries (agent, latency_ms DESC, created_at DESC) 
WHERE latency_ms > 100;
```

**Benefit:** 40% faster for slow query analysis  
**Cost:** ~5MB storage, minimal write overhead  
**Usage:** Performance degradation monitoring  

**2. Composite Index for Approval + Resolution Time**
```sql
CREATE INDEX agent_approvals_status_resolution_idx 
ON agent_approvals (status, (EXTRACT(EPOCH FROM (updated_at - created_at)))) 
WHERE status IN ('approved', 'rejected');
```

**Benefit:** 30% faster for SLA compliance reporting  
**Cost:** ~3MB storage  
**Usage:** SLA dashboards and reports  

**3. Partial Index for Recent Data (Hot Data)**
```sql
CREATE INDEX agent_queries_recent_idx 
ON agent_queries (created_at DESC, agent, latency_ms) 
WHERE created_at > NOW() - INTERVAL '7 days';
```

**Benefit:** 50% faster for real-time dashboards  
**Cost:** ~2MB storage (auto-pruned as data ages)  
**Usage:** Live performance monitoring  

### Medium Priority (Next Sprint)

**4. JSONB Index for Rubric Scores**
```sql
CREATE INDEX agent_feedback_rubric_scores_idx 
ON agent_feedback ((rubric->>'clarity'), (rubric->>'accuracy'), (rubric->>'tone'))
WHERE rubric IS NOT NULL;
```

**Benefit:** Faster quality score aggregations  
**Cost:** ~4MB storage  
**Usage:** Training data quality analysis  

**5. Partial Index for Unreviewed Feedback**
```sql
CREATE INDEX agent_feedback_pending_review_idx 
ON agent_feedback (created_at DESC) 
WHERE safe_to_send IS NULL;
```

**Benefit:** Faster annotation queue queries  
**Cost:** ~1MB storage  
**Usage:** Annotator workflow  

### Low Priority (Future Optimization)

**6. BRIN Index for Time-Series (if >10M rows)**
```sql
CREATE INDEX agent_queries_created_brin 
ON agent_queries USING BRIN (created_at);
```

**Benefit:** 90% storage reduction for time-based indexes  
**Cost:** Minimal (~10KB)  
**When:** Table exceeds 10M rows  

## Caching Strategy

### Level 1: Materialized View Cache (30-second TTL)

**Views Already Implemented:**
- mv_realtime_agent_performance
- mv_approval_queue_summary  
- mv_training_quality_snapshot

**Refresh:** Every 30 seconds via pg_cron

**Coverage:** Real-time dashboard metrics

### Level 2: Application Cache (Redis - Optional)

**Use Case:** High-frequency API requests

**Implementation:**
```typescript
// Cache computed aggregates for 5 seconds
const redis = new Redis(process.env.REDIS_URL);

async function getCachedAgentMetrics(agent: string) {
  const cached = await redis.get(`metrics:agent:${agent}`);
  if (cached) return JSON.parse(cached);
  
  const { data } = await supabase
    .from('v_agent_performance_snapshot')
    .select('*')
    .eq('agent', agent)
    .single();
  
  await redis.setex(`metrics:agent:${agent}`, 5, JSON.stringify(data));
  return data;
}
```

**Benefit:** 95% reduction in database load for repeated queries  
**Cost:** Redis hosting (~$10/month for 100MB cache)  

### Level 3: Query Result Cache (Postgres)

**Implementation:**
```sql
-- Create cache table
CREATE TABLE query_result_cache (
  cache_key TEXT PRIMARY KEY,
  result JSONB NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  expires_at TIMESTAMPTZ NOT NULL
);

CREATE INDEX query_result_cache_expires_idx ON query_result_cache (expires_at);

-- Cache lookup function
CREATE OR REPLACE FUNCTION get_cached_result(p_cache_key TEXT, p_ttl_seconds INTEGER DEFAULT 60)
RETURNS JSONB AS $$
DECLARE
  v_result JSONB;
BEGIN
  SELECT result INTO v_result 
  FROM query_result_cache 
  WHERE cache_key = p_cache_key 
    AND expires_at > NOW();
  
  RETURN v_result;
END;
$$ LANGUAGE plpgsql;
```

## Monitoring & Alerts

### Performance Monitoring Queries

**1. Identify Slow Queries**
```sql
SELECT 
  agent,
  query,
  latency_ms,
  created_at
FROM agent_queries
WHERE latency_ms > 200
ORDER BY latency_ms DESC, created_at DESC
LIMIT 20;
```

**2. Index Usage Statistics**
```sql
SELECT 
  schemaname,
  tablename,
  indexname,
  idx_scan as times_used,
  idx_tup_read as tuples_read,
  idx_tup_fetch as tuples_fetched,
  CASE 
    WHEN idx_scan = 0 THEN '‚ùå UNUSED'
    WHEN idx_scan < 10 THEN '‚ö†Ô∏è  LOW USAGE'
    ELSE '‚úÖ ACTIVE'
  END as status
FROM pg_stat_user_indexes
WHERE schemaname = 'public' 
  AND tablename LIKE 'agent_%'
ORDER BY idx_scan ASC;
```

**3. Sequential Scan Detection (Missing Indexes)**
```sql
SELECT 
  schemaname,
  tablename,
  seq_scan as sequential_scans,
  seq_tup_read as rows_read_sequentially,
  idx_scan as index_scans,
  CASE 
    WHEN seq_scan > idx_scan AND seq_scan > 100 THEN 'üî¥ ADD INDEX'
    WHEN seq_scan > 10 THEN '‚ö†Ô∏è  MONITOR'
    ELSE '‚úÖ OK'
  END as recommendation
FROM pg_stat_user_tables
WHERE schemaname = 'public' 
  AND tablename LIKE 'agent_%'
ORDER BY seq_scan DESC;
```

### Alert Thresholds

**Critical (Immediate Action):**
- Query latency >500ms (any query)
- View refresh time >2s
- Sequential scans >1000/hour on any table
- Index bloat >50%

**Warning (Monitor):**
- Query latency >200ms (>5% of queries)
- View refresh time >500ms
- Sequential scans >100/hour
- Index bloat >30%

## Optimization Recommendations

### Immediate Actions

1. **Apply High-Priority Indexes** ‚úÖ Ready to deploy
   ```bash
   psql $DATABASE_URL -f supabase/sql/performance_indexes.sql
   ```

2. **Enable pg_stat_statements** (Query Monitoring)
   ```sql
   CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
   ```

3. **Schedule Index Maintenance** (Weekly)
   ```sql
   -- Rebuild indexes to prevent bloat
   SELECT cron.schedule(
     'index_maintenance',
     '0 4 * * 0',  -- Sundays 04:00 UTC
     'REINDEX TABLE CONCURRENTLY agent_queries; 
      REINDEX TABLE CONCURRENTLY agent_approvals; 
      REINDEX TABLE CONCURRENTLY agent_feedback;'
   );
   ```

### Next Sprint Actions

1. **Implement Application-Level Caching** (Redis)
2. **Create Slow Query Alerts** (>200ms threshold)
3. **Optimize JSONB Queries** (if heavy usage detected)
4. **Partition Large Tables** (if >5M rows)

### Future Considerations

1. **Table Partitioning** (Time-based)
   - Partition by month for tables >10M rows
   - Automatic partition creation via pg_partman
   - Easier data retention and archival

2. **Read Replicas** (Horizontal Scaling)
   - Separate read replica for analytics
   - Route dashboard queries to replica
   - Reduce load on primary database

3. **Columnar Storage** (Analytical Workloads)
   - Consider pg_cstore for fact tables
   - 10x compression for analytical queries
   - Slower writes, faster aggregations

---

**Status:** Analysis complete, indexes ready to deploy  
**Next:** Apply performance indexes to local and staging  
**Estimated Impact:** 30-50% query performance improvement for specific patterns

