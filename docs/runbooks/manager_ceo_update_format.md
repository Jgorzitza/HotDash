---
epoch: 2025.10.E1
doc: docs/runbooks/manager_ceo_update_format.md
owner: manager
last_reviewed: 2025-10-13
expires: 2025-10-20
---

# Manager â†’ CEO Update Format

**Purpose**: Standardized format for manager's end-of-session CEO updates  
**File**: `artifacts/manager/CEO_UPDATES.md` (single file, appended each shutdown)  
**Frequency**: Every manager shutdown  
**Time to complete**: 10-15 minutes

---

## ğŸ“‹ UPDATE TEMPLATE

**Copy this template and fill in for each shutdown**:

```markdown
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## CEO UPDATE â€” YYYY-MM-DD HH:MM UTC
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

**Session Duration**: [X hours]  
**Date**: YYYY-MM-DD  
**Manager**: [Your session focus]

---

### ğŸ“Š OVERALL PROJECT STATUS

**Launch Target**: Oct 13-15, 2025  
**Current Status**: [On track / Delayed / At risk]  
**Completion**: [XX]% â†’ Launch Ready

**Breakdown**:
- Infrastructure: [XX]% (Services deployed, databases ready, etc.)
- Core Features: [XX]% (5 tiles, approval queue, etc.)
- Code Quality: [XX]% (TypeScript clean, tests passing, etc.)
- Documentation: [XX]% (Training, runbooks, etc.)
- Process: [XX]% (Agents following procedures, etc.)

**Overall Health**: ğŸŸ¢ Good / ğŸŸ¡ Concerns / ğŸ”´ Critical Issues

---

### ğŸ¯ SESSION ACCOMPLISHMENTS

**Major Wins**:
1. [Key accomplishment from this session]
2. [Another major achievement]
3. [Third win if applicable]

**Blockers Removed**:
- [Blocker X] â†’ Resolved by [Agent] in [time]
- [Blocker Y] â†’ Resolved by [Agent] in [time]

**Direction Files Cleaned**:
- [X] files cleaned ([total lines removed])
- Average size: [XX] lines (target: 200, limit: 400)

---

### ğŸš¨ CURRENT BLOCKERS

**P0 - Launch Blocking**:
1. **[Blocker Title]**
   - Impact: [Why it blocks launch]
   - Owner: [Agent]
   - Status: [In progress / Assigned / Escalated]
   - Deadline: [Time]
   - ETA to resolve: [Hours]

**P1 - Important**:
1. **[Issue Title]**
   - Impact: [Effect on project]
   - Owner: [Agent]
   - Timeline: [Days]

**Blockers Resolved Today**: [Count]  
**New Blockers Found**: [Count]

---

### ğŸ‘¥ AGENT PERFORMANCE RANKINGS

**Scoring Criteria** (out of 10):
- Code Quality (20%): Clean code, no errors, tests passing
- Blocker Response Time (20%): How fast they resolve issues
- Task Execution (15%): Complete work accurately with evidence
- Launch Contribution (15%): Work that moves us toward launch
- Independent Problem Solving (10%): Fix issues without hand-holding
- North Star Alignment (10%): Work supports 5 tiles and operator value
- Evidence Quality (5%): Clear logs, artifacts, proofs
- MCP Tool Usage (5%): Using MCPs, not training data
- Feedback Compliance (5%): Logging properly in their file
- Collaboration (5%): Helping other agents, clear handoffs

---

### ğŸ† TOP 3 PERFORMERS (This Session)

**ğŸ¥‡ #1: [Agent Name] - [X.X]/10**

**What They Did Well**:
1. [Specific achievement - be detailed]
2. [Another strength demonstrated]

**Their Self-Assessment**: [Quote from their performance review]

**Process Improvements for Them**:
1. [One change they should implement]
2. [Another improvement]

**Manager's Critical Feedback**: [Honest assessment of what they could do better]

**Prize**: ğŸŒŸ [Recognition - e.g., "MVP - Build Blocker Destroyer"]

---

**ğŸ¥ˆ #2: [Agent Name] - [X.X]/10**

**What They Did Well**:
1. [Achievement]
2. [Strength]

**Their Self-Assessment**: [Quote]

**Process Improvements**:
1. [Improvement]
2. [Another]

**Manager's Critical Feedback**: [What to improve]

**Prize**: â­ [Recognition]

---

**ğŸ¥‰ #3: [Agent Name] - [X.X]/10**

**What They Did Well**:
1. [Achievement]
2. [Strength]

**Their Self-Assessment**: [Quote]

**Process Improvements**:
1. [Improvement]

**Manager's Critical Feedback**: [What to improve]

**Prize**: âœ¨ [Recognition]

---

### ğŸ“Š ALL AGENT PERFORMANCE SCORES

**By Rank** (Highest to Lowest):

| Rank | Agent | Score | Status | Key Metric |
|------|-------|-------|--------|------------|
| 1 | [Agent] | [X.X]/10 | ğŸŸ¢ Excellent | [What they excel at] |
| 2 | [Agent] | [X.X]/10 | ğŸŸ¢ Excellent | [What they excel at] |
| 3 | [Agent] | [X.X]/10 | ğŸŸ¢ Excellent | [What they excel at] |
| 4 | [Agent] | [X.X]/10 | ğŸŸ¢ Good | [Strength] |
| 5 | [Agent] | [X.X]/10 | ğŸŸ¢ Good | [Strength] |
| ... | ... | ... | ... | ... |
| 16 | [Agent] | [X.X]/10 | ğŸ”´ Needs Work | [What needs fixing] |
| 17 | [Agent] | [X.X]/10 | ğŸ”´ Struggling | [Issue] |
| 18 | [Agent] | [X.X]/10 | ğŸ”´ Not Performing | [Problem] |

**Performance Distribution**:
- ğŸŸ¢ Excellent (8.0-10.0): [X] agents
- ğŸŸ¡ Good (6.0-7.9): [X] agents
- ğŸŸ  Needs Improvement (4.0-5.9): [X] agents
- ğŸ”´ Struggling (<4.0): [X] agents

---

### ğŸ“ˆ INDIVIDUAL AGENT ASSESSMENTS

**[Agent Name] - [X.X]/10 - Rank #[X]**

**Scoring Breakdown**:
- Code Quality: [X]/10 - [Comment]
- Blocker Response: [X]/10 - [Avg response time: XX min]
- Task Execution: [X]/10 - [X tasks complete, Y accurate]
- Launch Contribution: [X]/10 - [What they delivered for launch]
- Problem Solving: [X]/10 - [Independent solutions vs escalations]
- North Star Alignment: [X]/10 - [Their score + your assessment]
- Evidence Quality: [X]/10 - [Logs clear? Artifacts organized?]
- MCP Tool Usage: [X]/10 - [Used MCPs? Or training data?]
- Feedback Compliance: [X]/10 - [Logging properly? Violations?]
- Collaboration: [X]/10 - [Helped others? Clear handoffs?]

**What They Did Well** (From their review):
1. [Quote their self-assessment]
2. [Their identified strength]

**What They Screwed Up** (From their review):
- [Quote their honest mistake]
- Root cause: [Quote]
- Prevention: [Quote]

**Manager's Assessment**:
- âœ… **Strengths**: [2-3 specific things they excel at]
- âš ï¸ **Needs Work**: [1-2 specific improvements needed]
- ğŸ¯ **Next Session Focus**: [What they should prioritize]

**Process Improvements for Next Run**:
1. [Specific change to implement]
2. [Another improvement]

**Feedback for Agent**: [Direct message to include in their direction file]

---

**[Repeat for all 18 agents]**

---

### ğŸ–ï¸ PRIZES & RECOGNITION

**Top 3 Performers**:
1. ğŸ¥‡ **[#1 Agent]**: MVP Award - "Build Blocker Destroyer" 
   - Special recognition: [What made them #1]
   - Reward: [e.g., First pick on next interesting task, mentioned in launch announcement]
   
2. ğŸ¥ˆ **[#2 Agent]**: Excellence Award - "[Custom Title]"
   - Special recognition: [What they did exceptionally]
   - Reward: [Recognition]

3. ğŸ¥‰ **[#3 Agent]**: Achievement Award - "[Custom Title]"
   - Special recognition: [What stood out]
   - Reward: [Recognition]

**Special Recognition Categories**:
- ğŸ”¥ **Fastest Blocker Resolution**: [Agent] - [XX] min avg
- ğŸ¯ **Perfect North Star Alignment**: [Agent] - 10/10 score
- ğŸ“Š **Best Evidence Quality**: [Agent] - Exemplary documentation
- ğŸ¤ **Best Collaboration**: [Agent] - Helped [X] other agents
- ğŸ’¡ **Best Innovation**: [Agent] - [Creative solution to problem]

---

### ğŸ“Š MANAGER PERFORMANCE REVIEW

**My Score This Session**: [X.X]/10

**What I Did Well**:
1. [Specific accomplishment]
2. [Another strength]

**What I Screwed Up**:
1. [Specific mistake - be brutally honest]
   - Why it happened: [Root cause]
   - How to prevent: [Solution]

**Process Changes Implemented**:
1. [Change made this session]
2. [Another improvement]

**North Star Alignment**:
- Did I keep agents focused on 5 tiles? [Yes/No - examples]
- Did I remove blockers quickly? [Average response time: XX min]
- Did I prevent drift? [Yes/No - how many agents redirected]
- Did I maintain clean directions? [Files cleaned: X, avg size: XX lines]

**Improvements for Next Session**:
1. [Specific change to implement]
2. [Another improvement to try]

**Time Management**:
- Blocker identification: [XX]% of time
- Direction cleanup: [XX]% of time
- Agent coordination: [XX]% of time
- Firefighting: [XX]% of time

**Effectiveness**:
- Blockers removed: [X] in [total time]
- Agents redirected from drift: [X]
- Direction files cleaned: [X]
- Average agent utilization: [XX]% (not idle)

---

### ğŸ¯ RECOMMENDATIONS FOR CEO

**Strategic**:
1. [High-level recommendation]
2. [Another strategic insight]

**Tactical**:
1. [Immediate action needed]
2. [Resource needs]

**Risks**:
1. [Risk identified] - Mitigation: [Plan]
2. [Another risk] - Mitigation: [Plan]

---

### ğŸ“… NEXT SESSION PRIORITIES

**Critical Path for Next Session**:
1. [First priority]
2. [Second priority]
3. [Third priority]

**Agent Focus Areas**:
- Engineer: [Specific work]
- QA: [Specific work]
- Data: [Specific work]
- Others: [Status]

**Manager Focus**:
- [What I'll concentrate on next session]

---

**Session Complete**: YYYY-MM-DD HH:MM UTC  
**Next Update**: [When next session ends]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ–ï¸ SUGGESTED PRIZE CATEGORIES

**Weekly/Session Prizes**:
- ğŸ¥‡ **MVP (Most Valuable Player)**: Top overall performer
- ğŸ”¥ **Blocker Buster**: Fastest/most blocker resolutions
- ğŸ¯ **North Star Champion**: Perfect alignment to 5 tiles
- ğŸ“Š **Evidence Extraordinaire**: Best documentation/artifacts
- ğŸ’¡ **Innovation Award**: Most creative problem solving
- ğŸ¤ **Team Player**: Best collaboration/helping others
- âš¡ **Speed Demon**: Highest quality output in shortest time
- ğŸ›¡ï¸ **Quality Guardian**: Zero bugs, perfect code
- ğŸ“ **MCP Master**: Best use of MCP tools vs training data
- ğŸ§¹ **Clean Code Crusader**: Cleanest, most maintainable code

**Prize Ideas**:
- First pick on next interesting/challenging task
- Mentioned in launch announcement/credits
- "Agent of the Week" badge in their direction file
- Control over their own task priority (within reason)
- Extra autonomy (less check-ins if performing well)
- Showcase their work in demo to CEO
- Input on future feature priorities

---

## ğŸ“Š PERFORMANCE SCORING RUBRIC

### Code Quality (20 points max)
- 10: Perfect - Zero errors, all tests pass, clean commits
- 8: Excellent - Minor issues, quickly fixed
- 6: Good - Some errors but addressed
- 4: Needs work - Multiple errors, sloppy
- 2: Poor - Broken code, no testing
- 0: Failing - Cannot compile, blocks others

### Blocker Response Time (20 points max)
- 10: <30 min average response
- 8: 30-60 min average
- 6: 1-2 hours average
- 4: 2-4 hours average
- 2: 4-8 hours average
- 0: >8 hours or ignored

### Task Execution Accuracy (15 points max)
- 15: 100% of tasks complete with perfect evidence
- 12: 90%+ complete, minor evidence gaps
- 9: 75%+ complete, some rework needed
- 6: 50%+ complete, significant issues
- 3: <50% complete or mostly incorrect
- 0: No completed tasks or all wrong

### Launch Contribution (15 points max)
- 15: Critical path work, directly enables launch
- 12: Important launch work, supporting features
- 9: Helpful but not critical
- 6: Tangential to launch
- 3: Not launch-related work
- 0: Working against launch (drift)

### Independent Problem Solving (10 points max)
- 10: Solves all issues independently with creative solutions
- 8: Solves most issues, minimal escalation
- 6: Needs some guidance, good execution
- 4: Requires frequent guidance
- 2: Cannot proceed without constant direction
- 0: Blocked on trivial issues

### North Star Alignment (10 points max)
- 10: Perfect alignment - all work supports 5 tiles/operator value
- 8: Strong alignment - 80%+ work aligned
- 6: Decent - 60%+ aligned, some drift
- 4: Poor - 40%+ aligned, significant drift
- 2: Misaligned - mostly non-tile work
- 0: Completely off mission

### Evidence Quality (5 points max)
- 5: Perfect - timestamps, commands, outputs, organized
- 4: Excellent - minor gaps
- 3: Good - adequate documentation
- 2: Poor - missing evidence
- 1: Bad - no artifacts
- 0: No evidence

### MCP Tool Usage (5 points max)
- 5: Always uses MCPs, validates all patterns
- 4: Mostly uses MCPs
- 3: Sometimes uses MCPs
- 2: Rarely uses MCPs
- 1: Prefers training data
- 0: Never uses MCPs, training data only

### Feedback Compliance (5 points max)
- 5: Perfect logging, no violations
- 4: Good logging, minor issues
- 3: Adequate logging
- 2: Poor logging, some violations
- 1: Bad logging, many violations
- 0: No logging or major violations

### Collaboration (5 points max)
- 5: Helps other agents, clear handoffs, unblocks others
- 4: Good collaboration
- 3: Adequate teamwork
- 2: Isolated, doesn't help others
- 1: Blocks other agents
- 0: Actively hinders collaboration

**Total Score**: Sum of all categories = [XX]/100 (convert to X.X/10)

---

## ğŸ¯ ADDITIONAL SCORING FACTORS

**Velocity** (Tasks/Hour):
- High performer: >3 tasks/hour
- Good: 1-3 tasks/hour
- Average: 0.5-1 tasks/hour
- Slow: <0.5 tasks/hour

**Accuracy** (Rework Required):
- Perfect: 0% rework
- Excellent: <10% rework
- Good: 10-25% rework
- Poor: >25% rework

**Blocker Creation** (How many blockers did they introduce):
- Perfect: 0 blockers created
- Good: 1 minor blocker
- Poor: 2+ blockers or 1 major blocker

**Drift Incidents** (Times redirected from non-aligned work):
- Perfect: 0 redirects
- Good: 1 redirect
- Poor: 2+ redirects

---

## ğŸ“‹ EXAMPLE AGENT ASSESSMENT

```markdown
**Engineer - 8.7/10 - Rank #2**

**Scoring Breakdown**:
- Code Quality: 9/10 - Clean code, fixed TypeScript errors
- Blocker Response: 8/10 - Avg 45 min response time
- Task Execution: 8/10 - 4/5 tasks complete accurately
- Launch Contribution: 10/10 - Critical path work (Agent SDK, Approval UI)
- Problem Solving: 9/10 - Fixed build failure independently
- North Star Alignment: 8/10 - Focused on 5 tiles
- Evidence Quality: 9/10 - Excellent logs and artifacts
- MCP Tool Usage: 7/10 - Used Context7 for React Router validation
- Feedback Compliance: 8/10 - Good logging, minimal violations
- Collaboration: 9/10 - Unblocked QA, helped Data with schema

**Total**: 87/100 = 8.7/10

**What They Did Well** (From their review):
1. "Fixed build failure in 20 minutes using MCP validation"
2. "Deployed Agent SDK services successfully"

**What They Screwed Up** (From their review):
- "Let TypeScript errors accumulate to 70+ before addressing"
- Root cause: "Didn't run typecheck frequently enough"
- Prevention: "Will run typecheck after every file change"

**Manager's Assessment**:
- âœ… **Strengths**: Fast problem solving, high code quality, strong MCP usage
- âš ï¸ **Needs Work**: Run checks more frequently, log work more consistently
- ğŸ¯ **Next Focus**: Complete Approval UI (P0), then CX Pulse tile (P1)

**Process Improvements for Next Run**:
1. Run `npm run typecheck` after every file change (prevent accumulation)
2. Log work every 30 min (not just at end of task)

**Feedback for Agent** (Added to their direction):
"Excellent work on build fix - that was critical. For next session, focus on Approval UI (P0). Your problem-solving speed is a huge asset. Keep it up!"

**Velocity**: 4.5 tasks/hour âš¡ (High performer)  
**Accuracy**: 95% (minimal rework)  
**Blockers Created**: 0  
**Drift Incidents**: 0
```

---

## ğŸ¯ MANAGER SELF-ASSESSMENT

**My Score This Session**: [X.X]/10

**What I Did Well**:
1. [Specific accomplishment]
2. [Another success]

**What I Screwed Up**:
1. [Specific mistake]
   - Why: [Root cause]
   - Fix: [Prevention]

**Process Changes Implemented This Session**:
1. [Change #1]
2. [Change #2]

**Metrics**:
- Blocker response time: [XX] min average
- Direction files cleaned: [X] files
- Agents redirected from drift: [X]
- Session duration: [X] hours
- Agent utilization: [XX]% (not idle)

**Effectiveness Assessment**:
- Did I identify blockers proactively? [Yes/No - examples]
- Did I maintain clean directions? [Yes/No - file sizes]
- Did I keep agents focused? [Yes/No - drift prevented]
- Did I remove blockers quickly? [Yes/No - avg time]
- Did I align all work to North Star? [Yes/No - how]

**Improvements for Next Session**:
1. [Specific change]
2. [Another improvement]

**Grade Myself**: [X.X]/10
- Reasoning: [Honest self-assessment]

---

### ğŸ¯ KEY METRICS

**Team Velocity**:
- Tasks completed this session: [X]
- Blockers removed: [X]
- Code commits: [X]
- Tests added/fixed: [X]
- Features shipped: [X]

**Team Quality**:
- Code quality: [XX]% (TypeScript errors, test pass rate)
- Evidence quality: [XX]% (agents with good logging)
- Process compliance: [XX]% (agents following procedures)
- MCP usage: [XX]% (agents using tools vs training)

**Project Health Trend**:
- Yesterday: [XX]% complete
- Today: [XX]% complete
- Change: +[X]% (or -[X]%)
- Velocity: [X] percentage points per day
- Days to launch: [X] (at current velocity)

---

### ğŸš¨ CONCERNS & ESCALATIONS

**Items Requiring CEO Decision**:
1. [Issue requiring your input]
2. [Resource need or strategic decision]

**Risks to Monitor**:
1. [Risk] - Probability: [XX]%, Impact: [High/Med/Low]
2. [Risk] - Probability: [XX]%, Impact: [High/Med/Low]

**Process Breakdowns**:
1. [Process not working] - Fix: [Proposed solution]

---

### ğŸ’¬ CEO ACTION ITEMS (If Any)

**Decisions Needed**:
- [ ] [Decision 1]
- [ ] [Decision 2]

**Approvals Needed**:
- [ ] [Approval 1]
- [ ] [Approval 2]

**Resources Needed**:
- [ ] [Resource 1]

---

**Update Complete**: YYYY-MM-DD HH:MM UTC  
**Next Update**: [Next shutdown time]  
**Manager Status**: [Ready for next session / Need CEO input]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“Š ADDITIONAL SUGGESTIONS FOR CEO UPDATES

**Items to consider including**:

1. **Technical Debt Tracker**:
   - New debt introduced this session
   - Debt paid down this session
   - Net change
   
2. **Launch Confidence Score**:
   - Percentage confidence we can launch on time
   - Factors affecting confidence
   - What would increase confidence

3. **Agent Learning Curve**:
   - Which agents are improving session-over-session
   - Which agents are plateauing or declining
   - Training/support needs

4. **Dependency Chain Status**:
   - Visual of who's waiting on whom
   - Bottleneck identification
   - Critical path health

5. **Innovation Highlights**:
   - Creative solutions discovered
   - Process improvements agents suggested
   - Unexpected wins

6. **Customer/Operator Impact**:
   - How does today's work translate to operator value?
   - Which tiles are now closer to functional?
   - What can operators do tomorrow they couldn't today?

7. **Competitive Positioning**:
   - Features that differentiate from competitors
   - Speed to market updates
   - Unique value delivered

8. **Resource Efficiency**:
   - Agent hours spent vs value delivered
   - Most efficient agents (value per hour)
   - Resource allocation recommendations

---

**Created**: 2025-10-13  
**Owner**: Manager  
**Purpose**: Standard format for CEO updates ensuring consistent, comprehensive communication  
**Location**: docs/runbooks/manager_ceo_update_format.md

