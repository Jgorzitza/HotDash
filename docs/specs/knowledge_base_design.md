# Knowledge Base Design — AI Customer Support Learning System

**File:** `docs/specs/knowledge_base_design.md`  
**Owner:** ai-knowledge agent  
**Version:** 1.0  
**Effective:** 2025-10-15  
**Status:** Design Spec

---

## 1) Purpose

Build a **self-improving knowledge base** that:
- Learns from human edits to AI-drafted customer replies
- Extracts patterns from HITL grading data (tone/accuracy/policy)
- Identifies recurring customer issues and solutions
- Improves ai-customer agent responses over time
- Provides contextual knowledge retrieval for drafting replies

**Core Principle:** "Agents propose actions; humans approve or correct; the system learns."

---

## 2) Knowledge Base Structure

### 2.1 KB Article Schema

```sql
create table if not exists kb_articles (
  id bigint generated by default as identity primary key,
  
  -- Core content
  question text not null,                    -- Customer question/issue pattern
  answer text not null,                      -- Approved answer template
  category text not null,                    -- See categories below
  tags text[] not null default '{}',         -- Searchable tags
  
  -- Quality & confidence
  confidence_score decimal(3,2) not null default 0.50,  -- 0.00-1.00
  usage_count int not null default 0,       -- Times used in drafts
  success_count int not null default 0,     -- Times approved without edits
  avg_tone_grade decimal(3,2),              -- Average tone grade (1-5)
  avg_accuracy_grade decimal(3,2),          -- Average accuracy grade (1-5)
  avg_policy_grade decimal(3,2),            -- Average policy grade (1-5)
  
  -- Metadata
  source text not null,                      -- 'human_edit', 'template', 'extracted'
  created_by text not null,                  -- Agent or user ID
  last_used_at timestamptz,
  created_at timestamptz default now(),
  updated_at timestamptz default now(),
  
  -- Search optimization
  embedding vector(1536),                    -- OpenAI text-embedding-3-small
  
  -- Constraints
  constraint valid_confidence check (confidence_score between 0 and 1),
  constraint valid_grades check (
    (avg_tone_grade is null or avg_tone_grade between 1 and 5) and
    (avg_accuracy_grade is null or avg_accuracy_grade between 1 and 5) and
    (avg_policy_grade is null or avg_policy_grade between 1 and 5)
  )
);

-- Indexes for performance
create index kb_articles_category_idx on kb_articles(category);
create index kb_articles_confidence_idx on kb_articles(confidence_score desc);
create index kb_articles_tags_idx on kb_articles using gin(tags);
create index kb_articles_embedding_idx on kb_articles using ivfflat(embedding vector_cosine_ops);
create index kb_articles_last_used_idx on kb_articles(last_used_at desc nulls last);
```

### 2.2 Categories

**Primary categories** (aligned with customer support domains):

1. **orders** — Order status, tracking, modifications, cancellations
2. **shipping** — Shipping methods, ETAs, delays, international shipping
3. **returns** — Return policy, RMA process, refunds, exchanges
4. **products** — Product details, specifications, compatibility, availability
5. **technical** — Website issues, account problems, checkout errors
6. **policies** — Privacy, terms, warranties, guarantees

**Tags** provide fine-grained classification within categories:
- `order_tracking`, `order_modification`, `order_cancellation`
- `shipping_delay`, `shipping_international`, `shipping_cost`
- `return_policy`, `return_process`, `refund_timeline`
- `product_availability`, `product_specs`, `product_compatibility`
- `account_login`, `checkout_error`, `payment_issue`
- `privacy_policy`, `warranty_info`, `terms_of_service`

### 2.3 Learning Edits Table

Track human edits to AI drafts for continuous learning:

```sql
create table if not exists kb_learning_edits (
  id bigint generated by default as identity primary key,
  
  -- Link to approval
  approval_id bigint references approvals(id) on delete cascade,
  conversation_id bigint not null,           -- Chatwoot conversation ID
  
  -- Draft vs final
  ai_draft text not null,                    -- Original AI-generated draft
  human_final text not null,                 -- Human-approved final version
  edit_distance int not null,                -- Levenshtein distance
  edit_ratio decimal(3,2) not null,          -- edit_distance / length(ai_draft)
  
  -- Grading
  tone_grade int check (tone_grade between 1 and 5),
  accuracy_grade int check (accuracy_grade between 1 and 5),
  policy_grade int check (policy_grade between 1 and 5),
  
  -- Context
  customer_question text not null,
  category text,
  tags text[] default '{}',
  
  -- Extracted learnings
  kb_article_id bigint references kb_articles(id),  -- If created KB article
  learning_type text check (learning_type in (
    'tone_improvement',
    'factual_correction', 
    'policy_clarification',
    'template_refinement',
    'new_pattern'
  )),
  
  -- Metadata
  reviewer text not null,
  created_at timestamptz default now()
);

create index kb_learning_edits_approval_idx on kb_learning_edits(approval_id);
create index kb_learning_edits_category_idx on kb_learning_edits(category);
create index kb_learning_edits_grades_idx on kb_learning_edits(tone_grade, accuracy_grade, policy_grade);
create index kb_learning_edits_type_idx on kb_learning_edits(learning_type);
```

### 2.4 Recurring Issues Table

Identify and track recurring customer issues:

```sql
create table if not exists kb_recurring_issues (
  id bigint generated by default as identity primary key,
  
  -- Issue identification
  issue_pattern text not null,               -- Normalized issue description
  category text not null,
  tags text[] not null default '{}',
  
  -- Frequency tracking
  occurrence_count int not null default 1,
  first_seen_at timestamptz not null default now(),
  last_seen_at timestamptz not null default now(),
  
  -- Resolution
  kb_article_id bigint references kb_articles(id),  -- Linked KB article
  resolution_status text check (resolution_status in (
    'unresolved',
    'kb_created',
    'escalated',
    'product_issue',
    'policy_update_needed'
  )) not null default 'unresolved',
  
  -- Impact
  avg_resolution_time_minutes int,
  customer_satisfaction_score decimal(3,2),  -- If available from Chatwoot
  
  -- Metadata
  created_at timestamptz default now(),
  updated_at timestamptz default now()
);

create index kb_recurring_issues_category_idx on kb_recurring_issues(category);
create index kb_recurring_issues_count_idx on kb_recurring_issues(occurrence_count desc);
create index kb_recurring_issues_status_idx on kb_recurring_issues(resolution_status);
create index kb_recurring_issues_last_seen_idx on kb_recurring_issues(last_seen_at desc);
```

---

## 3) Learning Extraction Pipeline

### 3.1 Workflow: Draft → Review → Learn

```
1. AI drafts reply (ai-customer agent)
   ↓
2. Draft stored as Chatwoot Private Note
   ↓
3. Human reviews and edits (HITL)
   ↓
4. Human approves with grades (tone/accuracy/policy)
   ↓
5. Public reply sent
   ↓
6. Learning extraction triggered
   ↓
7. Analyze edits and grades
   ↓
8. Update KB or create new article
   ↓
9. Update confidence scores
   ↓
10. Feed to ai-customer for improved drafts
```

### 3.2 Learning Triggers

**When to extract learnings:**

1. **High-quality approval** (all grades ≥ 4, minimal edits)
   - Action: Increase confidence of used KB articles
   - Action: Create new KB article if novel pattern

2. **Significant edits** (edit_ratio > 0.3)
   - Action: Analyze what changed (tone, facts, policy)
   - Action: Create learning_edit record
   - Action: Update or create KB article

3. **Low grades** (any grade ≤ 2)
   - Action: Flag KB article for review
   - Action: Decrease confidence score
   - Action: Analyze failure pattern

4. **Recurring pattern** (same issue ≥ 3 times in 7 days)
   - Action: Create recurring_issue record
   - Action: Prioritize KB article creation
   - Action: Alert manager if product/policy issue

### 3.3 Edit Analysis

**Categorize human edits by type:**

```typescript
interface EditAnalysis {
  editType: 'tone_improvement' | 'factual_correction' | 'policy_clarification' | 'template_refinement' | 'new_pattern';
  confidence: number;  // 0-1
  suggestedAction: 'update_kb' | 'create_kb' | 'flag_review' | 'no_action';
  extractedKnowledge?: {
    question: string;
    answer: string;
    category: string;
    tags: string[];
  };
}
```

**Analysis heuristics:**

- **Tone improvement:** Sentiment analysis shows human version more empathetic
- **Factual correction:** Specific facts changed (dates, prices, policies)
- **Policy clarification:** Policy-related keywords added/modified
- **Template refinement:** Structure improved but core content same
- **New pattern:** Novel question/answer not in existing KB

### 3.4 Confidence Score Updates

**Formula for KB article confidence:**

```
new_confidence = (
  (success_count / usage_count) * 0.4 +
  (avg_tone_grade / 5) * 0.2 +
  (avg_accuracy_grade / 5) * 0.3 +
  (avg_policy_grade / 5) * 0.1
)
```

**Update rules:**

- Approved without edits (edit_ratio < 0.1): `success_count++`, `usage_count++`
- Approved with minor edits (0.1 ≤ edit_ratio < 0.3): `usage_count++`
- Approved with major edits (edit_ratio ≥ 0.3): `usage_count++`, decrease confidence
- Rejected or grade ≤ 2: Decrease confidence significantly

**Confidence thresholds:**

- ≥ 0.80: High confidence — use freely in drafts
- 0.60-0.79: Medium confidence — use with caution
- 0.40-0.59: Low confidence — flag for review
- < 0.40: Very low confidence — disable or archive

---

## 4) Knowledge Retrieval System

### 4.1 Retrieval Flow

When ai-customer agent drafts a reply:

```
1. Receive customer message
   ↓
2. Extract question intent and keywords
   ↓
3. Query KB with semantic search (embeddings)
   ↓
4. Filter by confidence ≥ 0.60
   ↓
5. Rank by relevance + confidence + recency
   ↓
6. Return top 3-5 KB articles
   ↓
7. Use as context for draft generation
   ↓
8. Track which KB articles were used
```

### 4.2 Semantic Search

**Embedding generation:**
- Use OpenAI `text-embedding-3-small` (1536 dimensions)
- Generate embeddings for both questions and answers
- Store in `kb_articles.embedding` column

**Search query:**

```sql
select 
  id,
  question,
  answer,
  category,
  tags,
  confidence_score,
  1 - (embedding <=> query_embedding) as similarity
from kb_articles
where 
  confidence_score >= 0.60
  and (category = $1 or $1 is null)
order by 
  (1 - (embedding <=> query_embedding)) * confidence_score desc,
  last_used_at desc nulls last
limit 5;
```

**Hybrid search** (combine semantic + keyword):
- Semantic search via embeddings (primary)
- Keyword search via tags (secondary)
- Combine scores with weighted average

### 4.3 Context Injection

**Format for ai-customer agent:**

```
KNOWLEDGE BASE CONTEXT:

[Article 1 - Confidence: 0.85]
Q: {question}
A: {answer}
Tags: {tags}
Last used: {last_used_at}

[Article 2 - Confidence: 0.78]
...

Use this knowledge to draft your reply. Adapt the language to match the customer's tone while maintaining accuracy and policy compliance.
```

---

## 5) Quality Metrics

### 5.1 KB Article Quality

**Per-article metrics:**

- **Confidence score:** 0-1 (formula in 3.4)
- **Usage rate:** Times used / total drafts in category
- **Success rate:** Approvals without edits / usage_count
- **Average grades:** tone, accuracy, policy (1-5 scale)
- **Recency:** Days since last_used_at

**Quality thresholds:**

- **Excellent:** confidence ≥ 0.80, success_rate ≥ 0.80, avg_grades ≥ 4.5
- **Good:** confidence ≥ 0.70, success_rate ≥ 0.70, avg_grades ≥ 4.0
- **Fair:** confidence ≥ 0.60, success_rate ≥ 0.60, avg_grades ≥ 3.5
- **Poor:** Below fair thresholds — flag for review or archive

### 5.2 System-Wide Metrics

**Overall KB health:**

- **Coverage:** % of customer questions matched to KB articles
- **Draft quality:** % of AI drafts approved with minimal edits (edit_ratio < 0.1)
- **Learning velocity:** New KB articles created per week
- **Confidence distribution:** % of articles in each confidence tier

**Target metrics (M2+):**

- Coverage ≥ 70% of customer questions
- Draft quality ≥ 60% approved with minimal edits
- Learning velocity ≥ 5 new articles per week (initially)
- Confidence distribution: ≥ 40% high confidence articles

### 5.3 Learning Pipeline Metrics

**Extraction effectiveness:**

- **Edit capture rate:** % of approvals with edits captured in kb_learning_edits
- **KB creation rate:** % of significant edits resulting in new KB articles
- **Confidence improvement:** Average confidence increase after learning
- **Grade trends:** Tone/accuracy/policy grades over time

**Monitoring:**

- Daily: New learning_edits, new KB articles, confidence changes
- Weekly: Grade trends, coverage changes, recurring issues
- Monthly: System-wide quality metrics, KB health report

---

## 6) Update Triggers & Maintenance

### 6.1 Automatic Updates

**Trigger KB article updates when:**

1. **High-quality approval** (grades ≥ 4, edit_ratio < 0.1)
   - Increment usage_count, success_count
   - Update avg_grades
   - Increase confidence_score
   - Update last_used_at

2. **Significant edit** (edit_ratio ≥ 0.3, grades ≥ 4)
   - Increment usage_count
   - Update avg_grades
   - Analyze edit for improvements
   - Consider creating new KB article variant

3. **Low grade** (any grade ≤ 2)
   - Increment usage_count
   - Update avg_grades (will decrease)
   - Decrease confidence_score
   - Flag for manual review

4. **Recurring pattern detected** (≥ 3 occurrences in 7 days)
   - Create kb_recurring_issues record
   - Prioritize KB article creation
   - Alert manager if unresolved

### 6.2 Manual Review Triggers

**Flag for human review when:**

- Confidence drops below 0.40
- Consecutive low grades (≥ 3 grades ≤ 2)
- High edit ratio (≥ 0.5) on multiple uses
- Conflicting information detected
- Policy changes require updates

### 6.3 Archival & Cleanup

**Archive KB articles when:**

- Not used in 90 days AND confidence < 0.50
- Superseded by newer, higher-confidence article
- Policy/product changes make obsolete
- Manually flagged for archival

**Cleanup process:**

- Move to `kb_articles_archive` table
- Preserve for audit trail
- Remove from active search
- Update related records

---

## 7) Integration Points

### 7.1 With ai-customer Agent

**Agent queries KB before drafting:**

```typescript
// In ai-customer agent instructions
const kbContext = await fetchKBContext({
  customerMessage: message.content,
  category: inferCategory(message.content),
  minConfidence: 0.60,
  limit: 5
});

// Include in agent prompt
const instructions = `
You are drafting a customer support reply.

${kbContext}

Draft a reply that:
- Uses knowledge from the KB articles above
- Matches the customer's tone
- Is accurate and policy-compliant
- Is empathetic and helpful
`;
```

**Track KB usage:**

```typescript
// After draft created
await trackKBUsage({
  approvalId: approval.id,
  kbArticleIds: usedArticles.map(a => a.id),
  draft: aiDraft
});
```

### 7.2 With Approvals System

**On approval with grades:**

```typescript
// Trigger learning extraction
await extractLearning({
  approvalId: approval.id,
  aiDraft: approval.evidence.draft,
  humanFinal: approval.receipts.sentMessage,
  grades: {
    tone: grading.tone,
    accuracy: grading.accuracy,
    policy: grading.policy
  },
  reviewer: approval.reviewer,
  conversationId: approval.evidence.conversationId
});
```

### 7.3 With Chatwoot

**Conversation context:**

- Fetch conversation history for context
- Extract customer question/issue
- Identify category and tags
- Link to Chatwoot conversation ID for audit

---

## 8) Implementation Phases

### Phase 1: Foundation (Week 1)
- ✅ Create KB schema (tables, indexes)
- ✅ Seed initial KB articles from templates
- ✅ Implement basic retrieval (semantic search)
- ✅ Test KB context injection in ai-customer

### Phase 2: Learning Pipeline (Week 2)
- ✅ Implement edit capture on approval
- ✅ Build edit analysis logic
- ✅ Create learning_edits records
- ✅ Implement confidence score updates

### Phase 3: Extraction & Creation (Week 3)
- ✅ Build KB article extraction from edits
- ✅ Implement recurring issue detection
- ✅ Create automated KB article creation
- ✅ Add manual review workflow

### Phase 4: Optimization (Week 4)
- ✅ Tune confidence score formula
- ✅ Optimize search ranking
- ✅ Implement archival process
- ✅ Add monitoring dashboards

---

## 9) Success Criteria

**Phase 1 (Foundation):**
- [ ] KB schema deployed to Supabase
- [ ] ≥ 20 seed articles across all categories
- [ ] Semantic search returns relevant results
- [ ] ai-customer uses KB context in drafts

**Phase 2 (Learning):**
- [ ] 100% of approvals with edits captured
- [ ] Edit analysis correctly categorizes edit types
- [ ] Confidence scores update automatically
- [ ] Learning_edits table populated

**Phase 3 (Extraction):**
- [ ] ≥ 5 new KB articles created from learnings per week
- [ ] Recurring issues detected and tracked
- [ ] Manual review queue functional
- [ ] KB article quality improving over time

**Phase 4 (Optimization):**
- [ ] Draft quality ≥ 60% (minimal edits)
- [ ] Coverage ≥ 70% of customer questions
- [ ] Average grades ≥ 4.5 (tone), ≥ 4.7 (accuracy), ≥ 4.8 (policy)
- [ ] Confidence distribution: ≥ 40% high confidence

---

## 10) Open Questions

**For manager to resolve:**

1. **Embedding model:** Confirm OpenAI text-embedding-3-small or use alternative?
2. **Confidence formula:** Adjust weights based on business priorities?
3. **Manual review SLA:** How quickly should flagged articles be reviewed?
4. **Archival policy:** 90 days unused or different threshold?
5. **Integration timing:** When to activate KB in ai-customer agent?

---

## 11) Rollback Plan

**If KB degrades draft quality:**

1. Disable KB context injection in ai-customer
2. Revert to template-only drafting
3. Analyze which KB articles caused issues
4. Archive low-confidence articles
5. Re-enable with higher confidence threshold (≥ 0.80)

**Rollback artifacts:**

- Snapshot of KB articles before changes
- Backup of learning_edits table
- Configuration flags for KB enable/disable
- Monitoring alerts for quality degradation

---

**End of Knowledge Base Design Spec v1.0**

