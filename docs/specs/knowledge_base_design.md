# Knowledge Base Design — AI Customer Support Learning System

**File:** `docs/specs/knowledge_base_design.md`  
**Owner:** ai-knowledge agent  
**Version:** 1.0  
**Effective:** 2025-10-15  
**Status:** Design Spec

---

## 1) Purpose

Build a **self-improving knowledge base** that:

- Learns from human edits to AI-drafted customer replies
- Extracts patterns from HITL grading data (tone/accuracy/policy)
- Identifies recurring customer issues and solutions
- Improves ai-customer agent responses over time
- Provides contextual knowledge retrieval for drafting replies

**Core Principle:** "Agents propose actions; humans approve or correct; the system learns."

---

## 2) Knowledge Base Structure

### 2.1 KB Article Schema

```sql
create table if not exists kb_articles (
  id bigint generated by default as identity primary key,

  -- Core content
  question text not null,
  answer text not null,
  category text not null,
  tags text[] not null default '{}',

  -- Quality & confidence
  confidence_score decimal(3,2) not null default 0.50,
  usage_count int not null default 0,
  success_count int not null default 0,
  avg_tone_grade decimal(3,2),
  avg_accuracy_grade decimal(3,2),
  avg_policy_grade decimal(3,2),

  -- Metadata
  source text not null,
  created_by text not null,
  last_used_at timestamptz,
  created_at timestamptz default now(),
  updated_at timestamptz default now(),

  -- Search optimization
  embedding vector(1536),

  constraint valid_confidence check (confidence_score between 0 and 1),
  constraint valid_grades check (
    (avg_tone_grade is null or avg_tone_grade between 1 and 5) and
    (avg_accuracy_grade is null or avg_accuracy_grade between 1 and 5) and
    (avg_policy_grade is null or avg_policy_grade between 1 and 5)
  )
);
```

### 2.2 Categories

1. **orders** — Order status, tracking, modifications, cancellations
2. **shipping** — Shipping methods, ETAs, delays, international
3. **returns** — Return policy, RMA process, refunds, exchanges
4. **products** — Product details, specifications, compatibility
5. **technical** — Website issues, account problems, checkout errors
6. **policies** — Privacy, terms, warranties, guarantees

### 2.3 Learning Edits Table

```sql
create table if not exists kb_learning_edits (
  id bigint generated by default as identity primary key,
  approval_id bigint references approvals(id) on delete cascade,
  conversation_id bigint not null,

  ai_draft text not null,
  human_final text not null,
  edit_distance int not null,
  edit_ratio decimal(3,2) not null,

  tone_grade int check (tone_grade between 1 and 5),
  accuracy_grade int check (accuracy_grade between 1 and 5),
  policy_grade int check (policy_grade between 1 and 5),

  customer_question text not null,
  category text,
  tags text[] default '{}',

  kb_article_id bigint references kb_articles(id),
  learning_type text check (learning_type in (
    'tone_improvement',
    'factual_correction',
    'policy_clarification',
    'template_refinement',
    'new_pattern'
  )),

  reviewer text not null,
  created_at timestamptz default now()
);
```

### 2.4 Recurring Issues Table

```sql
create table if not exists kb_recurring_issues (
  id bigint generated by default as identity primary key,

  issue_pattern text not null,
  category text not null,
  tags text[] not null default '{}',

  occurrence_count int not null default 1,
  first_seen_at timestamptz not null default now(),
  last_seen_at timestamptz not null default now(),

  kb_article_id bigint references kb_articles(id),
  resolution_status text check (resolution_status in (
    'unresolved',
    'kb_created',
    'escalated',
    'product_issue',
    'policy_update_needed'
  )) not null default 'unresolved',

  avg_resolution_time_minutes int,
  customer_satisfaction_score decimal(3,2),

  created_at timestamptz default now(),
  updated_at timestamptz default now()
);
```

---

## 3) Learning Extraction Pipeline

### 3.1 Workflow

```
1. AI drafts reply → 2. Private Note → 3. Human reviews/edits → 4. Approves with grades
→ 5. Public reply sent → 6. Learning extraction → 7. Analyze edits → 8. Update KB
→ 9. Update confidence → 10. Feed to ai-customer
```

### 3.2 Learning Triggers

1. **High-quality approval** (grades ≥ 4, edit_ratio < 0.1) → Increase confidence, create KB if novel
2. **Significant edits** (edit_ratio > 0.3) → Analyze changes, create learning_edit, update KB
3. **Low grades** (any ≤ 2) → Flag for review, decrease confidence
4. **Recurring pattern** (≥ 3 in 7 days) → Create recurring_issue, prioritize KB creation

### 3.3 Confidence Score Formula

```
new_confidence = (
  (success_count / usage_count) * 0.4 +
  (avg_tone_grade / 5) * 0.2 +
  (avg_accuracy_grade / 5) * 0.3 +
  (avg_policy_grade / 5) * 0.1
)
```

**Thresholds:**

- ≥ 0.80: High confidence — use freely
- 0.60-0.79: Medium confidence — use with caution
- 0.40-0.59: Low confidence — flag for review
- < 0.40: Very low confidence — disable/archive

---

## 4) Knowledge Retrieval System

### 4.1 Semantic Search

**Embedding:** OpenAI text-embedding-3-small (1536 dimensions)

**Query:**

```sql
select id, question, answer, category, tags, confidence_score,
  1 - (embedding <=> query_embedding) as similarity
from kb_articles
where confidence_score >= 0.60
order by (1 - (embedding <=> query_embedding)) * confidence_score desc
limit 5;
```

### 4.2 Context Injection

```
KNOWLEDGE BASE CONTEXT:

[Article 1 - Confidence: 0.85]
Q: {question}
A: {answer}
Tags: {tags}

Use this knowledge to draft your reply. Adapt language to match customer tone while maintaining accuracy and policy compliance.
```

---

## 5) Quality Metrics

### 5.1 Per-Article Metrics

- **Confidence score:** 0-1 (formula in 3.3)
- **Usage rate:** Times used / total drafts in category
- **Success rate:** Approvals without edits / usage_count
- **Average grades:** tone, accuracy, policy (1-5)

**Quality tiers:**

- **Excellent:** confidence ≥ 0.80, success ≥ 0.80, grades ≥ 4.5
- **Good:** confidence ≥ 0.70, success ≥ 0.70, grades ≥ 4.0
- **Fair:** confidence ≥ 0.60, success ≥ 0.60, grades ≥ 3.5
- **Poor:** Below fair → flag for review/archive

### 5.2 System-Wide Metrics

**Target metrics (M2+):**

- Coverage ≥ 70% of customer questions
- Draft quality ≥ 60% approved with minimal edits
- Learning velocity ≥ 5 new articles/week
- Confidence distribution: ≥ 40% high confidence

---

## 6) Update Triggers & Maintenance

### 6.1 Automatic Updates

**On high-quality approval** (grades ≥ 4, edit_ratio < 0.1):

- Increment usage_count, success_count
- Update avg_grades, increase confidence_score
- Update last_used_at

**On significant edit** (edit_ratio ≥ 0.3, grades ≥ 4):

- Increment usage_count, update avg_grades
- Analyze edit, consider new KB article

**On low grade** (any ≤ 2):

- Increment usage_count, update avg_grades
- Decrease confidence_score, flag for review

**On recurring pattern** (≥ 3 in 7 days):

- Create kb_recurring_issues record
- Prioritize KB article creation, alert manager

### 6.2 Archival

**Archive when:**

- Not used in 90 days AND confidence < 0.50
- Superseded by newer article
- Policy/product changes make obsolete

---

## 7) Integration Points

### 7.1 With ai-customer Agent

```typescript
const kbContext = await fetchKBContext({
  customerMessage: message.content,
  category: inferCategory(message.content),
  minConfidence: 0.6,
  limit: 5,
});
```

### 7.2 With Approvals System

```typescript
await extractLearning({
  approvalId: approval.id,
  aiDraft: approval.evidence.draft,
  humanFinal: approval.receipts.sentMessage,
  grades: { tone, accuracy, policy },
  reviewer: approval.reviewer,
});
```

---

## 8) Implementation Phases

**Phase 1: Foundation** (Week 1)

- Create KB schema, seed articles, implement retrieval, test context injection

**Phase 2: Learning Pipeline** (Week 2)

- Implement edit capture, build analysis logic, create learning_edits, update confidence

**Phase 3: Extraction & Creation** (Week 3)

- Build KB extraction, implement recurring detection, automate creation, add review workflow

**Phase 4: Optimization** (Week 4)

- Tune confidence formula, optimize search, implement archival, add monitoring

---

## 9) Success Criteria

**Phase 1:** KB schema deployed, ≥ 20 seed articles, semantic search working, ai-customer uses KB

**Phase 2:** 100% edits captured, edit analysis working, confidence updates automatic

**Phase 3:** ≥ 5 new articles/week, recurring issues tracked, review queue functional

**Phase 4:** Draft quality ≥ 60%, coverage ≥ 70%, grades ≥ 4.5/4.7/4.8, ≥ 40% high confidence

---

## 10) Rollback Plan

**If KB degrades quality:**

1. Disable KB context in ai-customer
2. Revert to template-only drafting
3. Analyze problematic articles
4. Archive low-confidence articles
5. Re-enable with higher threshold (≥ 0.80)

**Artifacts:** KB snapshot, learning_edits backup, config flags, monitoring alerts

---

**End of Knowledge Base Design Spec v1.0**
